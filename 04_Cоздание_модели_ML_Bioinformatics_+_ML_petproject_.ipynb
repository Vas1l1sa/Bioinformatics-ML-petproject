{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vas1l1sa/Bioinformatics-ML-petproject/blob/main/04_C%D0%BE%D0%B7%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_ML_Bioinformatics_%2B_ML_petproject_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7U_AdtPkG4qQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "65TyiRakXmSn"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "from sklearn.exceptions import FitFailedWarning\n",
        "warnings.simplefilter(\"ignore\", FitFailedWarning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emnANW3VUTbb"
      },
      "source": [
        "### Как разделить здоровых людей и людей с гастритом на основании различий в их микробиоте кишечника?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t25ldFwJDoZ"
      },
      "source": [
        "**Будем осуществлять supervised learning для задачи классификации с использованием следующих моделей машинного обучения:**\n",
        "\n",
        "**1.   Логистическая регрессия**\n",
        "\n",
        "**2.   KNN**\n",
        "\n",
        "**3.   SVM**\n",
        "\n",
        "**4.   Базовые деревья решений**\n",
        "\n",
        "**5.   Random forests**\n",
        "\n",
        "**6.   Boosting и AdaBoosting**\n",
        "\n",
        "**7.   Градиентный бустинг**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEY2qqpptFKO"
      },
      "source": [
        "###**1. Общая подготовка данных перед машинным обучением**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GuPRbdwipc0a"
      },
      "outputs": [],
      "source": [
        "#загрузим полученный ранее датасет\n",
        "df_total = pd.read_csv('/content/drive/MyDrive/данные для петпроджекта/df_total.csv')\n",
        "df_total = df_total.drop(['not_null_sum'], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eTn6nWKx0Qn",
        "outputId": "c4596339-d014-46e0-b69e-b35735a3febf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(df_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zCBOg6rPqoLN"
      },
      "outputs": [],
      "source": [
        "#разделим данные на признаки и отклик\n",
        "\n",
        "X = df_total.drop(['Index'], axis=1)\n",
        "y = df_total['Index']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMYjVLd9wv00"
      },
      "source": [
        "**В данной задаче нормировка признаков не требуется, т.к. все данные в датасете - процентное содержание того или иного вида в образце, т.е. по сути они уже отнормированы**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTiWOfQixNw0"
      },
      "source": [
        "**Ввиду того, что датасет получился довольно маленьким, сделаем разбивку данных только на обучающую и тестовую выборки (без hold-out test set).**\n",
        "\n",
        "**Для подбора оптимальных гиперпараметров будем применять кросс-валидацию (GridSearchCV) для тестовой выборки, т.к. от изменения разбивки данных результаты ошибок тоже будут меняться.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DEakQV_vrgEB"
      },
      "outputs": [],
      "source": [
        "#разделим данные на тренировочную и тестовую выборки\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sja6I-hrp3GA"
      },
      "source": [
        "###**2. Создание модели бинарной классификации на основе алгоритма логистической регрессии**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AlukpuXbDuUF"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "test_model1 = LogisticRegression(random_state=42, max_iter=50000) #устанавливаем параметр random_state, чтобы при нескольких запусках GridSearchCV со скорректированным списком гиперпараметров результаты получались уточненными, а не совершенно новыми\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rrKu9dMy57oX"
      },
      "outputs": [],
      "source": [
        "#посмотрим информацию по гиперпараметрам этого алгоритма и на основании нее составим словарь param_grid\n",
        "#help(LogisticRegression())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bwtp_NHTvQr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b72af59-72c7-4b82-b64c-d4465178c753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.05, 'dual': True, 'solver': 'liblinear'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid1 = [\n",
        "    {'C': [0.01, 0.05, 0.06, 0.07, 0.075, 0.078, 0.079, 0.08, 0.081, 0.082, 0.085, 0.09, 0.1, 0.12, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.2, 1.5, 1.7, 1.9, 2, 3, 5, 7, 10, 12, 15], 'solver': ['lbfgs', 'newton-cg', 'sag', 'saga'], 'dual': [False]},\n",
        "    {'C': [0.01, 0.05, 0.06, 0.07, 0.075, 0.078, 0.079, 0.08, 0.081, 0.082, 0.085, 0.09, 0.1, 0.12, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.2, 1.5, 1.7, 1.9, 2, 3, 5, 7, 10, 12, 15], 'solver': ['liblinear'], 'dual': [True, False]},\n",
        "]\n",
        "#разбила param_grid1 на 2 части, чтобы не выпадали ошибки при переборе некоторых комбинаций solver и dual\n",
        "grid1 = GridSearchCV(test_model1, param_grid1, cv = 5, scoring='accuracy', error_score=np.nan)\n",
        "\n",
        "grid1.fit(X_train, y_train)\n",
        "grid1.best_params_\n",
        "#старые гиперпараметры от LogisticRegressionCV - {'Cs': 2, 'dual': False, 'solver': 'lbfgs'}\n",
        "#{'C': 0.08, 'dual': False, 'solver': 'saga'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k6FPnM1QETBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a90618-e46c-4e74-a0f2-0a76a1ed9349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "logistic_regression_model = LogisticRegression(C = 0.05, dual=True, solver='liblinear')\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "y_pred1 = logistic_regression_model.predict(X_test)\n",
        "y_pred1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mxx_lJtuMx3"
      },
      "source": [
        "###**3. Создание модели бинарной классификации на основе алгоритма KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7QT14qk5uuW5"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "test_model2 = KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qh67S_I5uudr"
      },
      "outputs": [],
      "source": [
        "#help(KNeighborsClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YMaP2J4nuua8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89993e9-85cd-4981-cd0a-1888cf70d05f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid2 = {'n_neighbors': list(range(1,20))}\n",
        "\n",
        "grid2 = GridSearchCV(test_model2, param_grid2, cv=5, scoring='accuracy')\n",
        "grid2.fit(X_train, y_train)\n",
        "grid2.best_params_\n",
        "#{'n_neighbors': 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D0qXSh85xgKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d74fd09-0b24-4e94-ad32-3bcbf66b349f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred2 = knn_model.predict(X_test)\n",
        "y_pred2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoiHqeCnx91b"
      },
      "source": [
        "###**4. Создание модели бинарной классификации на основе алгоритма SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Lor1apF0uugw"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "from sklearn.svm import SVC\n",
        "test_model3 = SVC()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sMwEIjSZy2PX"
      },
      "outputs": [],
      "source": [
        "#help(SVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H3bOTKduyoV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db63e92e-4fce-48d0-c4c3-c09272761851"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.465, 'kernel': 'sigmoid'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid3 = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [0.01, 0.1, 1, 1.2, 1.4, 1.45, 1.46, 1.465, 1.47, 1.475, 1.48, 1.5, 1.52, 1.55, 1.7, 2, 5, 10, 15, 20, 25, 30]}\n",
        "\n",
        "grid3 = GridSearchCV(test_model3, cv=5, param_grid = param_grid3, scoring='accuracy')\n",
        "grid3.fit(X_train, y_train)\n",
        "grid3.best_params_\n",
        "#когда мы получили какое-то предварительно хорошее значение 'C', потом обязательно добавляем в список для перебора ближайшие к этому числу значения и запускаем повторный поиск по сетке\n",
        "#{'C': 0.01, 'kernel': 'linear'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-1QWjPfw2__R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3a1fc3-de5c-4fac-8685-2e8fa68101b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "svm_model = SVC(C=1.465, kernel='sigmoid')\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred3 = svm_model.predict(X_test)\n",
        "y_pred3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zypps6GmYM1"
      },
      "source": [
        "###**5. Создание модели бинарной классификации на основе алгоритма базовых деревьев решений**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ieH8PqcJpA1o"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "test_model4 = DecisionTreeClassifier(random_state=42) #устанавливаем параметр random_state, чтобы при нескольких запусках GridSearchCV со скорректированным списком гиперпараметров результаты получались уточненными, а не совершенно новыми\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XMl1OTLppseX"
      },
      "outputs": [],
      "source": [
        "#help(DecisionTreeClassifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "G5lTe_q5pshH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7058015-5921-462b-bef8-7a9f91006dc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid4 = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'criterion': [\"gini\", \"entropy\", \"log_loss\"]}\n",
        "grid4 = GridSearchCV(test_model4, param_grid4, cv=5, scoring='accuracy')\n",
        "grid4.fit(X_train, y_train)\n",
        "grid4.best_params_\n",
        "#{'criterion': 'entropy', 'max_depth': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FEaNLvAhrgRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82358b6a-f8e7-48d8-e035-d0b8096adde2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "decision_tree_model = DecisionTreeClassifier(criterion='gini', max_depth=2)\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "y_pred4 = decision_tree_model.predict(X_test)\n",
        "y_pred4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQLmNLt8mxb8"
      },
      "source": [
        "###**6. Создание модели бинарной классификации на основе алгоритма Random forests**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3zmY7rEcpi-_"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "test_model5 = RandomForestClassifier(random_state=42) #устанавливаем параметр random_state, чтобы при нескольких запусках GridSearchCV со скорректированным списком гиперпараметров результаты получались уточненными, а не совершенно новыми"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_c1bjiClHlC1"
      },
      "outputs": [],
      "source": [
        "#help(RandomForestClassifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K47f1tilu6Ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdaac73-4717-42a9-fa1f-af1e4c98d6a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 'sqrt', 'n_estimators': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid5 = {'n_estimators': [5, 6, 7, 8, 9, 10, 12, 15, 20, 30, 40, 45, 50, 55, 60, 65, 70, 75, 80, 90, 100, 120, 140, 200, 300, 400, 500], 'max_features': ['sqrt', 'log2']}\n",
        "grid5 = GridSearchCV(test_model5, param_grid5, cv=5, scoring='accuracy', error_score=np.nan)\n",
        "grid5.fit(X_train, y_train)\n",
        "grid5.best_params_\n",
        "#когда мы получили какое-то предварительно хорошее значение 'n_estimators', потом обязательно добавляем в список для перебора ближайшие к этому числу значения и запускаем повторный поиск по сетке\n",
        "#{'max_features': 'sqrt', 'n_estimators': 10}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n6Hj22hNvrMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a0c302-7643-45c2-c050-a4cc9ebcae01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "random_forest_model = RandomForestClassifier(max_features='sqrt', n_estimators=8)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "y_pred5 = random_forest_model.predict(X_test)\n",
        "y_pred5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odBiE4y0mydr"
      },
      "source": [
        "###**7. Создание модели бинарной классификации на основе алгоритма Boosting и AdaBoosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6-QDtZkqpjoX"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "test_model6 = AdaBoostClassifier()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WwZbNYrK_6f-"
      },
      "outputs": [],
      "source": [
        "#help(AdaBoostClassifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KTP_EiZF9bfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3ce210-36b6-4037-c7d2-86b812877d67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid6 = {'n_estimators': [5, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150]}\n",
        "\n",
        "grid6 = GridSearchCV(test_model6, param_grid6, cv=5, scoring='accuracy')\n",
        "grid6.fit(X_train, y_train)\n",
        "grid6.best_params_\n",
        "#{'n_estimators': 30}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4tkVWel39doV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d468d5-9803-4414-9135-420333e717d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "ada_boosting_model = AdaBoostClassifier(n_estimators=10)\n",
        "ada_boosting_model.fit(X_train, y_train)\n",
        "y_pred6 = ada_boosting_model.predict(X_test)\n",
        "y_pred6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49sNCV5dnAWU"
      },
      "source": [
        "###**8. Создание модели бинарной классификации на основе алгоритма градиентного бустинга**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xwyAfSwTpkPn"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "test_model7 = GradientBoostingClassifier(random_state=42) #устанавливаем параметр random_state, чтобы при нескольких запусках GridSearchCV со скорректированным списком гиперпараметров результаты получались уточненными, а не совершенно новыми\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "alY5nW8oBld-"
      },
      "outputs": [],
      "source": [
        "#help(GradientBoostingClassifier())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2AfQis3BllG"
      },
      "outputs": [],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#param_grid7 = {'n_estimators': [10, 30, 50, 90, 100, 115, 118, 119, 120, 121, 122, 125, 150], 'learning_rate': [0.0005, 0.001, 0.0015, 0.002, 0.005, 0.01], 'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'max_features' : ['None', 'sqrt', 'log2'], 'loss' : ['log_loss', 'exponential']}\n",
        "param_grid7 = {'n_estimators': [118, 119, 120, 121, 122, 125], 'learning_rate': [0.0005, 0.001, 0.0015, 0.002], 'max_depth': [8, 9, 10, 11, 12], 'max_features' : ['log2'], 'loss' : ['exponential']}\n",
        "grid7 = GridSearchCV(test_model7, param_grid7, cv=5, scoring='accuracy')\n",
        "grid7.fit(X_train, y_train)\n",
        "grid7.best_params_\n",
        "#{'learning_rate': 0.0005,'loss': 'exponential','max_depth': 10,'max_features': 'log2','n_estimators': 118}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juUlqzE6FnSH"
      },
      "outputs": [],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "gradient_boosting_model = GradientBoostingClassifier(learning_rate=0.001, loss='exponential', max_depth=10, max_features='log2', n_estimators=120)\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "y_pred7 = gradient_boosting_model.predict(X_test)\n",
        "y_pred7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Em4P8ED9SBG"
      },
      "source": [
        "###**9. Напишем функцию для сравнения всех этих моделей между собой**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBss72yCiuFH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "def run_models(models, X_train, y_train, X_test, y_test):\n",
        "    for model in models:\n",
        "        print(f\"Evaluating model: {model.__class__.__name__}\")\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print('\\n')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "        ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
        "        plt.title('Confusion Matrix for the model')\n",
        "        plt.show()\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "\n",
        "models = [logistic_regression_model, knn_model, svm_model, decision_tree_model, random_forest_model, ada_boosting_model, gradient_boosting_model]\n",
        "\n",
        "run_models(models, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D8bFqg4Xf4z"
      },
      "source": [
        "###**10. Напишем функцию для выбора наилучшей модели машинного обучения для этой задачи**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBYJXhJcnTR5"
      },
      "source": [
        "**Выберем модель, которая показала наилучшие результаты. В нашем датасете классы сбалансированы, поэтому для оценки моделей можно смотреть на показатель accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rBfSsC5vzpx"
      },
      "outputs": [],
      "source": [
        "#посмотрим, у какой из воделей наилучшая метрика accuracy\n",
        "def best_accuracy(models, X_train, y_train, X_test, y_test):\n",
        "    best_accuracy = 0\n",
        "    models_with_best_accuracy = []\n",
        "\n",
        "    for model in models:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            models_with_best_accuracy = [model]\n",
        "        #посмотрим, нет ли моделей с одинаковым accuracy\n",
        "        elif accuracy == best_accuracy:\n",
        "          models_with_best_accuracy.append(model)\n",
        "\n",
        "    print(f\"Best model(s) by accuracy ({best_accuracy:}):\")\n",
        "    for model in models_with_best_accuracy:\n",
        "        print(f\" - {model.__class__.__name__}\", '\\n')\n",
        "    return models_with_best_accuracy\n",
        "\n",
        "\n",
        "models = [logistic_regression_model, knn_model, svm_model, decision_tree_model, random_forest_model, ada_boosting_model, gradient_boosting_model]\n",
        "best_models = best_accuracy(models, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWFEH9lG36w9"
      },
      "source": [
        "**Таким образом, модель на основе GradientBoostingClassifier показала наилучшие результаты по метрике accuracy и кол-ву False Negative результатов, что особенно важно для медицинских задач.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlLyApspUJNA"
      },
      "outputs": [],
      "source": [
        "gradient_boosting_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EByz3mLbzBJf"
      },
      "source": [
        "###**12. Проверим, нет ли переобучения у нашей модели, т.к. метрики показывают довольно высокие значения**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V3DUa33zFvu"
      },
      "outputs": [],
      "source": [
        "#посморим на лучший средний результат accuracy на кросс-валидации на обучающей выборке для ada_boosting_model\n",
        "best_cv_score = grid7.best_score_\n",
        "print(f'Лучший средний результат на кросс-валидации (accuracy): {best_cv_score}')\n",
        "\n",
        "#посморим на метрики accuracy и др. на тестовой выборке\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_test = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "test_precision = precision_score(y_test, y_pred_test)\n",
        "test_recall = recall_score(y_test, y_pred_test)\n",
        "test_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(f'Точность (accuracy) на тестовой выборке: {test_accuracy}')\n",
        "print(f'Точность (precision) на тестовой выборке: {test_precision}')\n",
        "print(f'Полнота (recall) на тестовой выборке: {test_recall}')\n",
        "print(f'F1-метрика на тестовой выборке: {test_f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Идеальный результат на кросс-валидации (1.0) может быть признаком того, что модель идеально обучается на фолдах кросс-валидации и имеет переобучение."
      ],
      "metadata": {
        "id": "wqdd_pCiF_Ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Скорректируем гиперпараметры нашей модели**"
      ],
      "metadata": {
        "id": "_ri1xcHQJZkz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpsC02iFJyAo"
      },
      "outputs": [],
      "source": [
        "#создадим модель логистической регрессии и подберем оптимальные гиперпараметры при помощи поиска по сетке и кросс-валидации\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "test_model7_new = GradientBoostingClassifier(random_state=42) #устанавливаем параметр random_state, чтобы при нескольких запусках GridSearchCV со скорректированным списком гиперпараметров результаты получались уточненными, а не совершенно новыми\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-isMoFMpJyAq"
      },
      "outputs": [],
      "source": [
        "#сделаем поиск по сетке для нахождения оптимальных гиперпараметров\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid7_new = {'n_estimators': [50, 60, 70, 80, 85, 87, 89, 90, 91, 92, 95, 100], 'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05], 'max_depth': [3, 4, 5, 6, 7], 'max_features' : ['sqrt'], 'loss' : ['exponential']}\n",
        "grid7_new = GridSearchCV(test_model7_new, param_grid7_new, cv=5, scoring='accuracy')\n",
        "grid7_new.fit(X_train, y_train)\n",
        "grid7_new.best_params_\n",
        "#{'learning_rate': 0.0005,'loss': 'exponential','max_depth': 10,'max_features': 'log2','n_estimators': 118}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fXgmJVPJyAr"
      },
      "outputs": [],
      "source": [
        "#создадим модель с найденными оптимальными гиперпараметрами\n",
        "gradient_boosting_model_new = GradientBoostingClassifier(learning_rate=0.01, loss='exponential', max_depth=4, max_features='sqrt', n_estimators=90)\n",
        "gradient_boosting_model_new.fit(X_train, y_train)\n",
        "y_pred7 = gradient_boosting_model_new.predict(X_test)\n",
        "y_pred7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Построим матрицу ошибок для скорректированной модели**"
      ],
      "metadata": {
        "id": "s0oVfV6UXTkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbTWPgviWIa6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "def run_models(models, X_train, y_train, X_test, y_test):\n",
        "    for model in models:\n",
        "        print(f\"Evaluating model: {model.__class__.__name__}\")\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'F1 Score: {f1:.4f}')\n",
        "        print('\\n')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "        ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
        "        plt.title('Confusion Matrix for the model')\n",
        "        plt.show()\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "\n",
        "models = [gradient_boosting_model_new]\n",
        "\n",
        "run_models(models, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKTDKNMhTmbD"
      },
      "outputs": [],
      "source": [
        "#посморим на лучший средний результат accuracy на кросс-валидации на обучающей выборке для ada_boosting_model\n",
        "best_cv_score = grid7_new.best_score_\n",
        "print(f'Лучший средний результат на кросс-валидации (accuracy): {best_cv_score}')\n",
        "\n",
        "#посморим на метрики accuracy и др. на тестовой выборке\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred_test = gradient_boosting_model_new.predict(X_test)\n",
        "\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "test_precision = precision_score(y_test, y_pred_test)\n",
        "test_recall = recall_score(y_test, y_pred_test)\n",
        "test_f1 = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(f'Точность (accuracy) на тестовой выборке: {test_accuracy}')\n",
        "print(f'Точность (precision) на тестовой выборке: {test_precision}')\n",
        "print(f'Полнота (recall) на тестовой выборке: {test_recall}')\n",
        "print(f'F1-метрика на тестовой выборке: {test_f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzV2YI7B5gkR"
      },
      "source": [
        "**Интерпретация метрик и их анализ на предмет переобучения**\n",
        "\n",
        "\n",
        "Точность 0.9947368421052631 на кросс-валидации говорит о том, что модель очень хорошо обучилась на данных из обучающей выборки.\n",
        "\n",
        "На тестовой выборке точность составляет 0.9759036144578314, а F1-метрика — 0.975, что всего лишь немного ниже, чем результаты кросс-валидации.\n",
        "Precision и recall также достаточно высоки и близки к результатам на обучении. Это говорит о том, что модель не сильно потеряла в качестве на данных, которых она ранее не видела.\n",
        "\n",
        "Обычно при переобучении модель показывает существенно лучшие результаты на кросс-валидации или обучающей выборке, чем на тестовых данных.\n",
        "Здесь же расхождение метрик минимальное, что указывает на то, что модель хорошо справляется и с новыми данными.\n",
        "\n",
        "Таким образом, переобучение, вероятно, отсутствует.\n",
        "Высокие значения всех метрик указывают на хороший подбор всех гиперпараметров и хорошее обучение модели - модель можно считать хорошо настроенной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh0Slx9sEJ0D"
      },
      "source": [
        "**Найдем еще несколько метрик для оценки нашей модели**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJZ8iiYmCsDr"
      },
      "outputs": [],
      "source": [
        "#найдем метрики AUC-ROC и PRC-AUC для gradient_boosting_model_new\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "\n",
        "\n",
        "gradient_boosting_model_new.fit(X_train, y_train)\n",
        "y_probs = gradient_boosting_model_new.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC-ROC: {roc_auc: }\")\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(f\"PRC-AUC: {prc_auc: }\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как мы видим по этим метрикам, модель очень хорошо справляется с задачей бинарной классификации, и вероятность ошибочной классификации (FP и FN) минимальна."
      ],
      "metadata": {
        "id": "7egpFj8jQt0-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGqF9pKPWWKb"
      },
      "source": [
        "###**13. Отдельно посмотрим на данные, которые модель классифицировала неверно**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp1xFSuAO1Zy"
      },
      "outputs": [],
      "source": [
        "#получим индексы ложнопредсказанных точек\n",
        "y_pred = gradient_boosting_model_new.predict(X_test)\n",
        "#получим массив индексов таких точек\n",
        "false_predictions = np.where(y_pred != y_test)[0]\n",
        "false_predictions\n",
        "#найдем строки с тамики индексами в нашем датасете\n",
        "false_row = df_total.iloc[false_predictions]\n",
        "false_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUKXLPn3WkJx"
      },
      "outputs": [],
      "source": [
        "#проверим, есть ли вообще в колонках ненулевые значения\n",
        "non_zero_values = false_row.applymap(lambda x: x if x != 0 else np.nan).dropna(axis=1, how='all')\n",
        "print(non_zero_values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHINv346SoH8"
      },
      "source": [
        "**Почему данный образец был ошибочно классифицирован?** Как мы видим, данная строка содержит числовые значения всего одного признака из 131, что дает слишком мало информации об исследуемом образце для корректной работы модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnWHklDWbgn8"
      },
      "source": [
        "###**14. Сохраним нашу модель**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWS6RjeRbi9C"
      },
      "outputs": [],
      "source": [
        "gastr_or_healthy_classification_model = gradient_boosting_model_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWQDFTqXbjAD"
      },
      "outputs": [],
      "source": [
        "#сохранение модели\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "dump(gastr_or_healthy_classification_model, '/content/drive/MyDrive/данные для петпроджекта/gastr_or_healthy_classification_model.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htV2h91cYX1Z"
      },
      "source": [
        "###**15. Определим, какие виды бактерий больше всего влияют на результат классификации и на основе этой информации создадим шаблон для загрузки новых данных в нашу модель**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Оценка корреляции признаков**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T8sqIdwAGUGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = gradient_boosting_model_new.feature_importances_\n",
        "\n",
        "\n",
        "feature_names = X_train.columns\n",
        "importances_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "\n",
        "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
        "importances_df = importances_df.reset_index(drop=True)\n",
        "print(importances_df.head(50))\n"
      ],
      "metadata": {
        "id": "4a3dtNe8Gjiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IiKlVuyARdo"
      },
      "outputs": [],
      "source": [
        "#посмотрим корреляцию признаков и отклика (какие признаки больше других влияют на отклик)\n",
        "\n",
        "col_names = importances_df['Feature'].tolist()\n",
        "col_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhjTqyFzAa08"
      },
      "outputs": [],
      "source": [
        "#создаем шаблон датафрейма, в самом начале которого располагаются самые важные поля для заполнения (они больше всего влияют на результат)\n",
        "new_data = pd.DataFrame()\n",
        "for i in col_names:\n",
        "  new_data1 = pd.DataFrame(({i: [ ]}))\n",
        "  new_data = pd.concat([new_data, new_data1], axis=1)\n",
        "new_data\n",
        "\n",
        "#сохраним датафрейм\n",
        "new_data.to_excel('/content/drive/MyDrive/данные для петпроджекта/шаблон для загрузки новых данных.xlsx')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iBZ8xplIl2Ks_vzYyZhrya9uQ62gv7WQ",
      "authorship_tag": "ABX9TyM+QNk7VHaLhphtaxa/VIJB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}